{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_u4bbsmAvxw"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "pQwAiT4mAxwQ",
        "outputId": "71e6b71d-1a0f-463f-8b47-e3c63c855f2f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "UCD3mwh0AzOg",
        "outputId": "1d0cb378-798c-4568-cfb0-28b869397f6e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3\n"
          ]
        }
      ],
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "V7LhdHSSVszj",
        "outputId": "dd0be8bb-f0a1-4651-a78a-51371ab35f1d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "class SentimentRNN(nn.Module):\n",
        "    def __init__(self,no_layers,vocab_size,hidden_dim,embedding_dim,drop_prob=0.5):\n",
        "        super(SentimentRNN,self).__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.no_layers = no_layers\n",
        "        self.vocab_size = vocab_size\n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        #lstm\n",
        "        self.lstm = nn.LSTM(input_size=embedding_dim,hidden_size=self.hidden_dim,\n",
        "                           num_layers=no_layers, batch_first=True)\n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        # linear and sigmoid layer\n",
        "        self.fc = nn.Linear(self.hidden_dim, output_dim)\n",
        "        self.sig = nn.Sigmoid()\n",
        "    def forward(self,x,hidden):\n",
        "        batch_size = x.size(0)\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)  # shape: B x S x Feature   since batch = True\n",
        "        #print(embeds.shape)  #[50, 500, 1000]\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        # dropout and fully connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        h0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        c0 = torch.zeros((self.no_layers,batch_size,self.hidden_dim)).to(device)\n",
        "        hidden = (h0,c0)\n",
        "        return hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "yCqWYE0u72w4",
        "outputId": "aa297720-37c5-4c0c-9006-f86ffee075af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Preprocess the data\n",
        "import os\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "def read_txt_files(folder_path, label):\n",
        "    data = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        with open(os.path.join(folder_path, filename), 'r', encoding='utf-8') as file:\n",
        "            review = file.read()\n",
        "            data.append((review, label))\n",
        "    return data\n",
        "\n",
        "# Path to the folders containing positive and negative reviews\n",
        "positive_folder = '/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3 /IMDB_reviews/aclImdb/train/pos'\n",
        "negative_folder = '/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3 /IMDB_reviews/aclImdb/train/neg'\n",
        "\n",
        "positive_folder_2 = '/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3 /IMDB_reviews/aclImdb/test/pos'\n",
        "negative_folder_2 = '/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3 /IMDB_reviews/aclImdb/test/neg'\n",
        "\n",
        "# Read positive and negative reviews\n",
        "positive_data = read_txt_files(positive_folder, label=1)\n",
        "negative_data = read_txt_files(negative_folder, label=0)\n",
        "positive_data_2 = read_txt_files(positive_folder_2, label=1)\n",
        "negative_data_2 = read_txt_files(negative_folder_2, label=0)\n",
        "\n",
        "# Combine positive and negative data\n",
        "all_data = positive_data + negative_data + positive_data_2 + negative_data_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "mhEWPMFkeom7",
        "outputId": "db554319-cf57-4fa8-e127-dff17f16fe25"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import json\n",
        "os.chdir('/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3 ')\n",
        "\n",
        "with open(\"all_data_IMDB.json\", \"w\") as outfile:\n",
        "    json.dump(all_data, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "juGEZ5bEf5sl",
        "outputId": "c5a04cc5-2c33-4786-f16f-277a9c667046"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "f = open('/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3/all_data_IMDB.json')\n",
        "all_data = json.load(f)\n",
        "\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "--IaUGgb_eCX",
        "outputId": "8cac2ed5-91ea-4f61-8474-27c5c64b68ef"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['What a good film! Made Men is a great action movie with lots of twists and turns. James Belushi is very good as an ex hood who has stolen 12 million from the boss who has to fend of the gangsters , hillbillies his wife and the local sheriff( Timothy Dalton).you wont be disappointed, jump on board and enjoy the ride. 8 out of 10', 1]\n",
            "\n",
            "[\"Being the prototype of the classical Errol Flynn adventure movie and having a good story as well as two more brilliant co-stars in Maureen O'Hara (what an exquisite beauty!) and Anthony Quinn, I can only recommend this movie to all those having even the slightest liking for romance and adventure.<br /><br />Hollywood at its best!\", 1]\n",
            "\n",
            "['Red Eye, a movie that id had wanted to see for awhile...Cillian Murphy plays Jack Ripner (jack the ripper) a managerial pose to Assassins, and his literally killer plan to knock off a highly profiled man and his family.<br /><br />An everyday woman \"Lisa\" (I think) is a normal woman, goes to work, home...worries...hates to fly.<br /><br />The death of her grandmother sends her on a flight which delayed several times.<br /><br />a flight where she meets Jack...an ordinary seeming guy, until he suavely reveals his profession and plans, which coincidentally include her in them, she is the key to the Keefe\\'s (sp?) death.<br /><br />She succeeds in saving them...but nearly the cost of her life is taken, Jack is beaten...the Keefs are saved...oh what a story *laughs* just kidding, the movie is really good actually, the best of last year...there are small things that you have to pay attention to earlier in the movie that play a GREAT importance to the movie later... (the Frankenstein pen) I watched it several times before catching all the little jokes and quirks...<br /><br />a must see for thriller fans no sexual, but there is a slight hint (the bathroom scene) (jack) \"Thanks for the quicky\" and the (female attendant) \"Ohhh...its gonna be ONE of those flights\" (second female attendant) \"Hey! this isn\\'t a motel\" you get the idea...', 1]\n",
            "\n",
            "[\"I have seen this film many times and I like all bad teachers want to give it ten out of ten but feel that it would be unfair to other good films. However, I do think that this is one of those rare gems: a perfect comedy. It is I would venture one of the greatest comic films of all times. Matthau and Lemmon are perfectly matched and mismatched. The script is so sharp that you need to staunch the bleeding. The story is well known and has already been described in other comments. The two leads give extraordinary performances, the girls are superb and the situations are side-splittingly funny. Not one swear-word in sight (mark that Hollywood, you don't have to swear to be funny, you have to be witty) and the move from stage to film is seamless. They don't make'em like this any more. Timeless.\", 1]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(all_data[0])\n",
        "print()\n",
        "print(all_data[1])\n",
        "print()\n",
        "print(all_data[2])\n",
        "print()\n",
        "print(all_data[3])\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jctIczvr_JVd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "bf6638d1-9773-43e6-934b-dbe18d2105f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing Html\n",
            "After Removing HTML tags: This is a demo testtext! \n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "\n",
            "Removing Punctuations\n",
            "After Removing Punctuations: fsd        sdfsdfdsvv  \n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "\n",
            "Removing URL\n",
            "After Removing URL:   notice the URL is removed\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "\n",
            "Removing Extra\n",
            "After Removing Extra: This looks soooooooo good!,I am so happpyyy\n",
            "---------------------------------------------------\n",
            "---------------------------------------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Function to clean html tags from a sentence\n",
        "import re\n",
        "def clean_html(sentence):\n",
        "    pattern = re.compile('<.*?>')\n",
        "    cleaned_text = re.sub(pattern,' ',sentence)\n",
        "    return cleaned_text\n",
        "\n",
        "print(\"Removing Html\")\n",
        "print('After Removing HTML tags:',clean_html('This is a demo testtext!<>'))\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print('\\n')\n",
        "\n",
        "#Function to keep only words containing letters A-Z and a-z.\n",
        "#this will remove all punctuations, special characters.\n",
        "def rem_pun(sentence):\n",
        "    cleaned_text  = re.sub('[^a-zA-Z]',' ',sentence)\n",
        "    return (cleaned_text)\n",
        "\n",
        "print(\"Removing Punctuations\")\n",
        "print(\"After Removing Punctuations:\",rem_pun(\"fsd*?~,,,( sdfsdfdsvv)#\"))\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"\\n\")\n",
        "\n",
        "#Remove URL from sentences.\n",
        "def rem_url(sen):\n",
        "    txt = re.sub(r\"http\\S+\", \" \", sen)\n",
        "    sen = re.sub(r\"www.\\S+\", \" \", txt)\n",
        "    return (sen)\n",
        "\n",
        "print(\"Removing URL\")\n",
        "print(\"After Removing URL:\",rem_url(\"https://colab.research.google.com/drive/1dG8sy949kwnxsOX6BN4Dkime6JdVjGqL#scrollTo=_0_gNhnK6TRY notice the URL is removed\"))\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"\\n\")\n",
        "\n",
        "#Remove words like 'ddddddddd', 'funnnnnn', 'coolllllll' etc. Preserves words like 'goods', 'cool', 'best' etc. We will remove all such words which has three consecutive repeating characters.\n",
        "def remove_extra(sen):\n",
        "    cleaned_text  = re.sub(\"\\s*\\b(?=\\w*(\\w)\\1{2,})\\w*\\b\",' ',sen)\n",
        "    return (cleaned_text)\n",
        "\n",
        "\n",
        "print(\"Removing Extra\")\n",
        "print(\"After Removing Extra:\",remove_extra(\"This looks soooooooo good!,I am so happpyyy\"))\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"---------------------------------------------------\")\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "vXCoovs3_OIv",
        "outputId": "76e9882c-265e-42e4-806f-07d67025bf56"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "for sentence in range(0, len(all_data)):\n",
        "\n",
        "  sent = all_data[sentence][0]\n",
        "\n",
        "  sent = clean_html(sent)\n",
        "  sent = rem_pun(sent)\n",
        "  sent = rem_url(sent)\n",
        "  sent = remove_extra(sent)\n",
        "  all_data[sentence][0] = sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "IcLRDHxJ_m9M",
        "outputId": "6f906438-4801-4267-b2b4-8209f1502649"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Convert all the words to lower case\n",
        "#Source https://github.com/saugatapaul1010/Amazon-Fine-Food-Reviews-Analysis\n",
        "import re\n",
        "\n",
        "def lower_case(x):\n",
        "    x = str(x).lower()\n",
        "    x = x.replace(\",000,000\", \" m\").replace(\",000\", \" k\").replace(\"′\", \"'\").replace(\"’\", \"'\")\\\n",
        "                           .replace(\"won't\", \" will not\").replace(\"cannot\", \" can not\").replace(\"can't\", \" can not\")\\\n",
        "                           .replace(\"n't\", \" not\").replace(\"what's\", \" what is\").replace(\"it's\", \" it is\")\\\n",
        "                           .replace(\"'ve\", \" have\").replace(\"'m\", \" am\").replace(\"'re\", \" are\")\\\n",
        "                           .replace(\"he's\", \" he is\").replace(\"she's\", \" she is\").replace(\"'s\", \" own\")\\\n",
        "                           .replace(\"%\", \" percent \").replace(\"₹\", \" rupee \").replace(\"$\", \" dollar \")\\\n",
        "                           .replace(\"€\", \" euro \").replace(\"'ll\", \" will\").replace(\"how's\",\" how has\").replace(\"y'all\",\" you all\")\\\n",
        "                           .replace(\"o'clock\",\" of the clock\").replace(\"ne'er\",\" never\").replace(\"let's\",\" let us\")\\\n",
        "                           .replace(\"finna\",\" fixing to\").replace(\"gonna\",\" going to\").replace(\"gimme\",\" give me\").replace(\"gotta\",\" got to\").replace(\"'d\",\" would\")\\\n",
        "                           .replace(\"daresn't\",\" dare not\").replace(\"dasn't\",\" dare not\").replace(\"e'er\",\" ever\").replace(\"everyone's\",\" everyone is\")\\\n",
        "                           .replace(\"'cause'\",\" because\")\n",
        "\n",
        "    x = re.sub(r\"([0-9]+)000000\", r\"\\1m\", x)\n",
        "    x = re.sub(r\"([0-9]+)000\", r\"\\1k\", x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6ScOECeMp9sp",
        "outputId": "ec77c200-c42b-4973-cd78-5aa53f385f4e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive reviews: 25000\n",
            "Negative reviews: 25000\n"
          ]
        }
      ],
      "source": [
        "count1 = 0\n",
        "count2 = 0\n",
        "\n",
        "for item in range(0, len(all_data)):\n",
        "  if all_data[item][1] == 1:\n",
        "    count1 += 1\n",
        "  else:\n",
        "    count2 += 1\n",
        "\n",
        "print(\"Positive reviews:\", count1)\n",
        "print(\"Negative reviews:\", count2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8LbaE7daEcw9",
        "outputId": "568be2bc-8a9c-4c34-8a69-3d4bde876a9b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(all_data[0][1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "SN5mPLc8IqVb",
        "outputId": "4b0f2be8-d2cb-41d6-e0d4-b910629f5ddd"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "50000\n",
            "['Being the prototype of the classical Errol Flynn adventure movie and having a good story as well as two more brilliant co stars in Maureen O Hara  what an exquisite beauty   and Anthony Quinn  I can only recommend this movie to all those having even the slightest liking for romance and adventure   Hollywood at its best ', 1]\n"
          ]
        }
      ],
      "source": [
        "print(type(all_data))\n",
        "print(len(all_data))\n",
        "print(all_data[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "_LF6cFdv2bW0",
        "outputId": "ac3c4b45-06c0-43ca-f7ee-1232b05b152a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import random\n",
        "random.shuffle(all_data)\n",
        "# all_data_small = all_data[0:40000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "aBxt9O7f2xft",
        "outputId": "0b5e0817-f9e3-4539-c41b-da5d513b10a0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I gave it a   instead of a   because I think  The Wild Women of Wongo  is worse  This is an exercise in patience  It s like having your teeth cleaned by a bad dental hygienist  There s no plot  There s no logic  There is certainly no acting  although the shark has some quality dialogue   We don t wonder about anything  We don t know how people got where they got  It s always amazing to me how things like this even get released  I agree with the previous writer that it isn t even funny bad  I know  It s about    minutes long and that will fill up about that much space on a DVD collection  It s like a paperweight  Or a bad painting you bought at a starving artists  sale  It covers the crack in the wall ',\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "all_data[560]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZevhyqXs88G6",
        "outputId": "1a91dff0-3373-49ab-ec4a-28766aed9c4f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99342\n",
            "Sample original text: It s Valentines Day and we decided to stay in  have a nice dinner  and watch this movie on TCM instead of going out  We re in our    s      s  love romance  and are both  softies  but this movie just bombed for us  it s hard to imagine that it was nominated for Oscars  etc  but I guess that was then   The cinematography was beautiful but for the most part the movie as a whole is terribly dated  Jennifer Jones  character made so many references to her being Eurasion that we started counting and after a while we were giggling every time she said it  Add to that the  theme song  played incessantly throughout the film and we couldn t wait for it to be over so we could watch the evening news \n",
            "Sample tokenized text: ['it', 's', 'valentines', 'day', 'and', 'we', 'decided', 'to', 'stay', 'in', 'have', 'a', 'nice', 'dinner', 'and', 'watch', 'this', 'movie', 'on', 'tcm', 'instead', 'of', 'going', 'out', 'we', 're', 'in', 'our', 's', 's', 'love', 'romance', 'and', 'are', 'both', 'softies', 'but', 'this', 'movie', 'just', 'bombed', 'for', 'us', 'it', 's', 'hard', 'to', 'imagine', 'that', 'it', 'was', 'nominated', 'for', 'oscars', 'etc', 'but', 'i', 'guess', 'that', 'was', 'then', 'the', 'cinematography', 'was', 'beautiful', 'but', 'for', 'the', 'most', 'part', 'the', 'movie', 'as', 'a', 'whole', 'is', 'terribly', 'dated', 'jennifer', 'jones', 'character', 'made', 'so', 'many', 'references', 'to', 'her', 'being', 'eurasion', 'that', 'we', 'started', 'counting', 'and', 'after', 'a', 'while', 'we', 'were', 'giggling', 'every', 'time', 'she', 'said', 'it', 'add', 'to', 'that', 'the', 'theme', 'song', 'played', 'incessantly', 'throughout', 'the', 'film', 'and', 'we', 'couldn', 't', 'wait', 'for', 'it', 'to', 'be', 'over', 'so', 'we', 'could', 'watch', 'the', 'evening', 'news']\n",
            "Sample numericalized text: [7, 12, 31165, 250, 2, 70, 862, 5, 763, 8, 27, 3, 328, 2707, 2, 103, 10, 15, 22, 6333, 300, 4, 158, 43, 70, 150, 8, 256, 12, 12, 110, 865, 2, 25, 195, 59864, 18, 10, 15, 41, 7923, 16, 178, 7, 12, 249, 5, 805, 11, 7, 13, 2239, 16, 3480, 498, 18, 9, 463, 11, 13, 93, 1, 618, 13, 310, 18, 16, 1, 89, 174, 1, 15, 14, 3, 221, 6, 1957, 2011, 1919, 1228, 104, 90, 36, 107, 1814, 5, 42, 109, 72766, 11, 70, 644, 7576, 2, 100, 3, 136, 70, 71, 11193, 171, 57, 54, 303, 7, 715, 5, 11, 1, 756, 589, 252, 14942, 468, 1, 19, 2, 70, 411, 21, 839, 16, 7, 5, 29, 121, 36, 70, 96, 103, 1, 2177, 1441]\n",
            "Sample label: 0\n",
            "Sample original text: Anthony Mann s westerns with Jimmy Stewart are slowly gaining for that director a position with John Ford and Howard Hawks as the best film director in that genre  He certainly knows how to give dimension to nice guy Stewart   in Mann s films there is an edge to Jimmy that is slowly demonstrated to the audience  In WINCHESTER     it was the relationship of Stewart to his brother and how it twists him into a figure of vengeance  Here it is a  I trust only myself  attitude  which leads to one complication after another  Even before the film properly begins he  as Jeff Webster  kills two of his hired cowboys who were helping on a cattle drive to Seattle because of some dispute  we never are clear about it   either they wanted to leave the cattle drive  or they tried to steal the cattle     He meets his match in Skagway  the port he has to get to in order to take his herd to Dawson  Skagway s boss is a so called law man named Gannon  John McIntyre  who reminds one of the real boss of Skagway in the  Gold Rush  Jefferson  Soapy  Smith and Judge Roy Bean  The problem is that neither Smith nor Bean would have gotten quite as sleazy as Gannon in turning every opportunity into a chance to make some money  Stewart s herd interrupted a public hanging   so  as a penalty fine  the herd is confiscated  to be sold later for Gannon s profit     Stewart is partner with Ben  Walter Brennan   who oddly enough won his last Oscar playing Judge Roy Bean   They are also joined by Rube Morris  Jay C  Flippen  and also meet two women  the sophisticated Rhonda Castle  Ruth Roman  and the friendly and helpful Renee Vallon  Corinne Calvert   Rhonda works closely with Gannon  but had helped Jeff earlier in fleeing the authorities in Seattle  However  she has a similar  I only trust myself  attitude to Jeff  She does offer him employment to get supplies for herself to Dawson  He  Ben  and Rube go but at night  while the others are asleep  they go back and steal back their cattle  Renee follows and warns them that Gannon and his associates are following  Jeff holds off Gannon long enough for the cattle herd to be brought over the Canadian border  although Gannon points out that since Jeff has to return by way of Skagway Gannon can wait until he does to hang him   The reunited party of Rhonda and Jeff split over the trail to take to Dawson  Jeff opting for a longer and safer route  After he is proved right  they go by his route and reach Dawson only to find there is a lawless element threatening the community due to the gold fields  The herd is sold to Rhonda  and Jeff  Ben  Rube  and Renee start prospecting  There is soon two groups in the town of Dawson  One led by Connie Gilchrist and Chubby Johnson want to build a decent town  But the Mounties won t be setting up a station in Dawson for months  The other  centering around the  dancehall  run by Rhonda  are in cahoots with Gannon who has a vast claim jumping scheme using his gang of gunslingers  Robert J  Wilke   really scary in one sequence with Chubby Johnson and Jay C  Flippen  Jack Elam  and Harry Morgan   Jeff wishes to steer clear of both  and head with his new wealth and Ben for a ranch they want in Utah  But will they get there  And will Jeff remain neutral   The performances are dandy here  including Stewart as a man who is willing to face all comers  but would otherwise be peaceful enough  Brennan is playing one of his patented old codgers  whose love of good coffee has unexpectedly bad results  Flippen is a drunk at first  but tragedy and responsibility shake him into a better frame of mind   and one who has a chance to verbally stab Stewart in the heart using Stewart s own words against him  McIntyre would achieve stardom on television in WAGON TRAIN replacing Ward Bond  but his work in Mann s films show his abilities as a villain  such as his trade post opportunist who outsmarts himself in WINCHESTER       He is  as is said elsewhere on this thread  really sleazy   but he has a sense of humor  Roman is an interesting blend of opportunist and human being  whose fate is determined by her better feelings  And Calvert is both a voice of conscience and a frontier  Gigi  aware that she is more than a young girl but a budding woman   Best of all is the Canadian Rockies background   as wonderful in its way as the use of Monument Valley by John Ford  Mann certainly did a first rate job directing this film  and the viewer will appreciate the results \n",
            "Sample tokenized text: ['anthony', 'mann', 's', 'westerns', 'with', 'jimmy', 'stewart', 'are', 'slowly', 'gaining', 'for', 'that', 'director', 'a', 'position', 'with', 'john', 'ford', 'and', 'howard', 'hawks', 'as', 'the', 'best', 'film', 'director', 'in', 'that', 'genre', 'he', 'certainly', 'knows', 'how', 'to', 'give', 'dimension', 'to', 'nice', 'guy', 'stewart', 'in', 'mann', 's', 'films', 'there', 'is', 'an', 'edge', 'to', 'jimmy', 'that', 'is', 'slowly', 'demonstrated', 'to', 'the', 'audience', 'in', 'winchester', 'it', 'was', 'the', 'relationship', 'of', 'stewart', 'to', 'his', 'brother', 'and', 'how', 'it', 'twists', 'him', 'into', 'a', 'figure', 'of', 'vengeance', 'here', 'it', 'is', 'a', 'i', 'trust', 'only', 'myself', 'attitude', 'which', 'leads', 'to', 'one', 'complication', 'after', 'another', 'even', 'before', 'the', 'film', 'properly', 'begins', 'he', 'as', 'jeff', 'webster', 'kills', 'two', 'of', 'his', 'hired', 'cowboys', 'who', 'were', 'helping', 'on', 'a', 'cattle', 'drive', 'to', 'seattle', 'because', 'of', 'some', 'dispute', 'we', 'never', 'are', 'clear', 'about', 'it', 'either', 'they', 'wanted', 'to', 'leave', 'the', 'cattle', 'drive', 'or', 'they', 'tried', 'to', 'steal', 'the', 'cattle', 'he', 'meets', 'his', 'match', 'in', 'skagway', 'the', 'port', 'he', 'has', 'to', 'get', 'to', 'in', 'order', 'to', 'take', 'his', 'herd', 'to', 'dawson', 'skagway', 's', 'boss', 'is', 'a', 'so', 'called', 'law', 'man', 'named', 'gannon', 'john', 'mcintyre', 'who', 'reminds', 'one', 'of', 'the', 'real', 'boss', 'of', 'skagway', 'in', 'the', 'gold', 'rush', 'jefferson', 'soapy', 'smith', 'and', 'judge', 'roy', 'bean', 'the', 'problem', 'is', 'that', 'neither', 'smith', 'nor', 'bean', 'would', 'have', 'gotten', 'quite', 'as', 'sleazy', 'as', 'gannon', 'in', 'turning', 'every', 'opportunity', 'into', 'a', 'chance', 'to', 'make', 'some', 'money', 'stewart', 's', 'herd', 'interrupted', 'a', 'public', 'hanging', 'so', 'as', 'a', 'penalty', 'fine', 'the', 'herd', 'is', 'confiscated', 'to', 'be', 'sold', 'later', 'for', 'gannon', 's', 'profit', 'stewart', 'is', 'partner', 'with', 'ben', 'walter', 'brennan', 'who', 'oddly', 'enough', 'won', 'his', 'last', 'oscar', 'playing', 'judge', 'roy', 'bean', 'they', 'are', 'also', 'joined', 'by', 'rube', 'morris', 'jay', 'c', 'flippen', 'and', 'also', 'meet', 'two', 'women', 'the', 'sophisticated', 'rhonda', 'castle', 'ruth', 'roman', 'and', 'the', 'friendly', 'and', 'helpful', 'renee', 'vallon', 'corinne', 'calvert', 'rhonda', 'works', 'closely', 'with', 'gannon', 'but', 'had', 'helped', 'jeff', 'earlier', 'in', 'fleeing', 'the', 'authorities', 'in', 'seattle', 'however', 'she', 'has', 'a', 'similar', 'i', 'only', 'trust', 'myself', 'attitude', 'to', 'jeff', 'she', 'does', 'offer', 'him', 'employment', 'to', 'get', 'supplies', 'for', 'herself', 'to', 'dawson', 'he', 'ben', 'and', 'rube', 'go', 'but', 'at', 'night', 'while', 'the', 'others', 'are', 'asleep', 'they', 'go', 'back', 'and', 'steal', 'back', 'their', 'cattle', 'renee', 'follows', 'and', 'warns', 'them', 'that', 'gannon', 'and', 'his', 'associates', 'are', 'following', 'jeff', 'holds', 'off', 'gannon', 'long', 'enough', 'for', 'the', 'cattle', 'herd', 'to', 'be', 'brought', 'over', 'the', 'canadian', 'border', 'although', 'gannon', 'points', 'out', 'that', 'since', 'jeff', 'has', 'to', 'return', 'by', 'way', 'of', 'skagway', 'gannon', 'can', 'wait', 'until', 'he', 'does', 'to', 'hang', 'him', 'the', 'reunited', 'party', 'of', 'rhonda', 'and', 'jeff', 'split', 'over', 'the', 'trail', 'to', 'take', 'to', 'dawson', 'jeff', 'opting', 'for', 'a', 'longer', 'and', 'safer', 'route', 'after', 'he', 'is', 'proved', 'right', 'they', 'go', 'by', 'his', 'route', 'and', 'reach', 'dawson', 'only', 'to', 'find', 'there', 'is', 'a', 'lawless', 'element', 'threatening', 'the', 'community', 'due', 'to', 'the', 'gold', 'fields', 'the', 'herd', 'is', 'sold', 'to', 'rhonda', 'and', 'jeff', 'ben', 'rube', 'and', 'renee', 'start', 'prospecting', 'there', 'is', 'soon', 'two', 'groups', 'in', 'the', 'town', 'of', 'dawson', 'one', 'led', 'by', 'connie', 'gilchrist', 'and', 'chubby', 'johnson', 'want', 'to', 'build', 'a', 'decent', 'town', 'but', 'the', 'mounties', 'won', 't', 'be', 'setting', 'up', 'a', 'station', 'in', 'dawson', 'for', 'months', 'the', 'other', 'centering', 'around', 'the', 'dancehall', 'run', 'by', 'rhonda', 'are', 'in', 'cahoots', 'with', 'gannon', 'who', 'has', 'a', 'vast', 'claim', 'jumping', 'scheme', 'using', 'his', 'gang', 'of', 'gunslingers', 'robert', 'j', 'wilke', 'really', 'scary', 'in', 'one', 'sequence', 'with', 'chubby', 'johnson', 'and', 'jay', 'c', 'flippen', 'jack', 'elam', 'and', 'harry', 'morgan', 'jeff', 'wishes', 'to', 'steer', 'clear', 'of', 'both', 'and', 'head', 'with', 'his', 'new', 'wealth', 'and', 'ben', 'for', 'a', 'ranch', 'they', 'want', 'in', 'utah', 'but', 'will', 'they', 'get', 'there', 'and', 'will', 'jeff', 'remain', 'neutral', 'the', 'performances', 'are', 'dandy', 'here', 'including', 'stewart', 'as', 'a', 'man', 'who', 'is', 'willing', 'to', 'face', 'all', 'comers', 'but', 'would', 'otherwise', 'be', 'peaceful', 'enough', 'brennan', 'is', 'playing', 'one', 'of', 'his', 'patented', 'old', 'codgers', 'whose', 'love', 'of', 'good', 'coffee', 'has', 'unexpectedly', 'bad', 'results', 'flippen', 'is', 'a', 'drunk', 'at', 'first', 'but', 'tragedy', 'and', 'responsibility', 'shake', 'him', 'into', 'a', 'better', 'frame', 'of', 'mind', 'and', 'one', 'who', 'has', 'a', 'chance', 'to', 'verbally', 'stab', 'stewart', 'in', 'the', 'heart', 'using', 'stewart', 's', 'own', 'words', 'against', 'him', 'mcintyre', 'would', 'achieve', 'stardom', 'on', 'television', 'in', 'wagon', 'train', 'replacing', 'ward', 'bond', 'but', 'his', 'work', 'in', 'mann', 's', 'films', 'show', 'his', 'abilities', 'as', 'a', 'villain', 'such', 'as', 'his', 'trade', 'post', 'opportunist', 'who', 'outsmarts', 'himself', 'in', 'winchester', 'he', 'is', 'as', 'is', 'said', 'elsewhere', 'on', 'this', 'thread', 'really', 'sleazy', 'but', 'he', 'has', 'a', 'sense', 'of', 'humor', 'roman', 'is', 'an', 'interesting', 'blend', 'of', 'opportunist', 'and', 'human', 'being', 'whose', 'fate', 'is', 'determined', 'by', 'her', 'better', 'feelings', 'and', 'calvert', 'is', 'both', 'a', 'voice', 'of', 'conscience', 'and', 'a', 'frontier', 'gigi', 'aware', 'that', 'she', 'is', 'more', 'than', 'a', 'young', 'girl', 'but', 'a', 'budding', 'woman', 'best', 'of', 'all', 'is', 'the', 'canadian', 'rockies', 'background', 'as', 'wonderful', 'in', 'its', 'way', 'as', 'the', 'use', 'of', 'monument', 'valley', 'by', 'john', 'ford', 'mann', 'certainly', 'did', 'a', 'first', 'rate', 'job', 'directing', 'this', 'film', 'and', 'the', 'viewer', 'will', 'appreciate', 'the', 'results']\n",
            "Sample numericalized text: [1979, 4434, 12, 2477, 17, 2021, 1418, 25, 1355, 10924, 16, 11, 153, 3, 2624, 17, 307, 1618, 2, 1756, 10405, 14, 1, 118, 19, 153, 8, 11, 502, 24, 421, 665, 85, 5, 196, 4793, 5, 328, 208, 1418, 8, 4434, 12, 105, 39, 6, 34, 1246, 5, 2021, 11, 6, 1355, 6985, 5, 1, 299, 8, 8117, 7, 13, 1, 623, 4, 1418, 5, 26, 577, 2, 85, 7, 1233, 87, 83, 3, 825, 4, 4426, 129, 7, 6, 3, 9, 1722, 62, 528, 2003, 61, 821, 5, 28, 19412, 100, 160, 59, 162, 1, 19, 2848, 819, 24, 14, 1930, 15674, 1147, 106, 4, 26, 2616, 8357, 35, 71, 2826, 22, 3, 6182, 1307, 5, 8484, 84, 4, 49, 13121, 70, 112, 25, 743, 44, 7, 345, 32, 456, 5, 554, 1, 6182, 1307, 40, 32, 752, 5, 2053, 1, 6182, 24, 893, 26, 1007, 8, 18257, 1, 10963, 24, 46, 5, 75, 5, 8, 626, 5, 188, 26, 8930, 5, 5101, 18257, 12, 1391, 6, 3, 36, 432, 1083, 124, 760, 11369, 307, 14415, 35, 1740, 28, 4, 1, 145, 1391, 4, 18257, 8, 1, 1640, 3137, 9029, 17374, 1340, 2, 1651, 2454, 4903, 1, 444, 6, 11, 1081, 1340, 913, 4903, 60, 27, 1921, 181, 14, 2949, 14, 11369, 8, 1595, 171, 1425, 83, 3, 563, 5, 94, 49, 289, 1418, 12, 8930, 7043, 3, 1027, 2452, 36, 14, 3, 7550, 480, 1, 8930, 6, 25604, 5, 29, 2956, 304, 16, 11369, 12, 7661, 1418, 6, 1910, 17, 1142, 2468, 10885, 35, 3084, 193, 379, 26, 236, 783, 392, 1651, 2454, 4903, 32, 25, 82, 4531, 33, 22474, 4435, 2948, 948, 19506, 2, 82, 886, 106, 358, 1, 3356, 16251, 1908, 4094, 3776, 2, 1, 2792, 2, 5783, 7424, 61341, 17530, 24520, 16251, 492, 3178, 17, 11369, 18, 67, 1613, 1930, 937, 8, 9294, 1, 5353, 8, 8484, 190, 54, 46, 3, 729, 9, 62, 1722, 528, 2003, 5, 1930, 54, 125, 1432, 87, 11516, 5, 75, 9255, 16, 800, 5, 5101, 24, 1142, 2, 22474, 141, 18, 31, 308, 136, 1, 396, 25, 2360, 32, 141, 144, 2, 2053, 144, 66, 6182, 7424, 1086, 2, 7325, 92, 11, 11369, 2, 26, 8989, 25, 954, 1930, 1714, 122, 11369, 194, 193, 16, 1, 6182, 8930, 5, 29, 816, 121, 1, 2333, 4054, 257, 11369, 798, 43, 11, 234, 1930, 46, 5, 993, 33, 95, 4, 18257, 11369, 48, 839, 364, 24, 125, 5, 2907, 87, 1, 9143, 980, 4, 16251, 2, 1930, 3351, 121, 1, 3660, 5, 188, 5, 5101, 1930, 16205, 16, 3, 1129, 2, 15913, 5184, 100, 24, 6, 2193, 204, 32, 141, 33, 26, 5184, 2, 2042, 5101, 62, 5, 167, 39, 6, 3, 17252, 1536, 3739, 1, 1802, 678, 5, 1, 1640, 4019, 1, 8930, 6, 2956, 5, 16251, 2, 1930, 1142, 22474, 2, 7424, 372, 58395, 39, 6, 521, 106, 3852, 8, 1, 490, 4, 5101, 28, 1540, 33, 9390, 21456, 2, 11160, 2415, 180, 5, 1676, 3, 530, 490, 18, 1, 27336, 379, 21, 29, 933, 55, 3, 1546, 8, 5101, 16, 1816, 1, 77, 18405, 185, 1, 52608, 487, 33, 16251, 25, 8, 23569, 17, 11369, 35, 46, 3, 3877, 2394, 3382, 4162, 774, 26, 1157, 4, 32069, 598, 1400, 43609, 64, 651, 8, 28, 695, 17, 11160, 2415, 2, 2948, 948, 19506, 647, 17160, 2, 1343, 2263, 1930, 3266, 5, 6247, 743, 4, 195, 2, 402, 17, 26, 168, 4543, 2, 1142, 16, 3, 5831, 32, 180, 8, 10464, 18, 81, 32, 75, 39, 2, 81, 1930, 2183, 9744, 1, 365, 25, 7815, 129, 574, 1418, 14, 3, 124, 35, 6, 1665, 5, 385, 30, 17106, 18, 60, 887, 29, 6774, 193, 10885, 6, 392, 28, 4, 26, 15551, 159, 52182, 630, 110, 4, 50, 3951, 46, 5300, 74, 1983, 19506, 6, 3, 1909, 31, 88, 18, 1614, 2, 4306, 4387, 87, 83, 3, 127, 1927, 4, 323, 2, 28, 35, 46, 3, 563, 5, 11775, 7670, 1418, 8, 1, 478, 774, 1418, 12, 198, 662, 446, 87, 14415, 60, 2800, 6059, 22, 679, 8, 4832, 1049, 8867, 3559, 1303, 18, 26, 161, 8, 4434, 12, 105, 116, 26, 3663, 14, 3, 1004, 140, 14, 26, 3519, 1113, 25036, 35, 35097, 313, 8, 8117, 24, 6, 14, 6, 303, 3284, 22, 10, 5461, 64, 2949, 18, 24, 46, 3, 281, 4, 454, 3776, 6, 34, 219, 3896, 4, 25036, 2, 389, 109, 630, 1991, 6, 2892, 33, 42, 127, 1375, 2, 24520, 6, 195, 3, 539, 4, 5235, 2, 3, 6620, 16804, 1895, 11, 54, 6, 52, 72, 3, 187, 241, 18, 3, 8994, 245, 118, 4, 30, 6, 1, 2333, 24140, 935, 14, 390, 8, 91, 95, 14, 1, 356, 4, 11224, 3726, 33, 307, 1618, 4434, 421, 117, 3, 88, 951, 294, 957, 10, 19, 2, 1, 500, 81, 1092, 1, 1983]\n",
            "Sample label: 1\n",
            "Sample original text: The best horror sci fi movie i have ever seen  I was myself in the Arctic  working for Canadian government   in a small northern station when I see this movie for the first time  needless to say I was in the mood   \n",
            "Sample tokenized text: ['the', 'best', 'horror', 'sci', 'fi', 'movie', 'i', 'have', 'ever', 'seen', 'i', 'was', 'myself', 'in', 'the', 'arctic', 'working', 'for', 'canadian', 'government', 'in', 'a', 'small', 'northern', 'station', 'when', 'i', 'see', 'this', 'movie', 'for', 'the', 'first', 'time', 'needless', 'to', 'say', 'i', 'was', 'in', 'the', 'mood']\n",
            "Sample numericalized text: [1, 118, 183, 843, 835, 15, 9, 27, 123, 108, 9, 13, 528, 8, 1, 12672, 755, 16, 2333, 1263, 8, 3, 395, 5449, 1546, 51, 9, 65, 10, 15, 16, 1, 88, 57, 3094, 5, 132, 9, 13, 8, 1, 1227]\n",
            "Sample label: 1\n"
          ]
        }
      ],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "# Tokenize the data\n",
        "tok_reviews = [tokenizer(lower_case(review)) for review, _ in all_data]\n",
        "\n",
        "# Build vocabulary\n",
        "vocab = build_vocab_from_iterator(tok_reviews, specials=[\"<unk>\"])\n",
        "vocab.set_default_index(vocab[\"<unk>\"])  # Handle unknown tokens\n",
        "print(len(vocab))\n",
        "\n",
        "def preprocess(data, vocab, max_sequence_length=512):\n",
        "    tok_reviews, labels = zip(*[(tokenizer(review), label) for review, label in data])\n",
        "\n",
        "    # Numericalize the sentences\n",
        "    numericalized_data = [[vocab[token] for token in sentence] for sentence in tok_reviews]\n",
        "\n",
        "    # Pad sequences\n",
        "    padded_sequences = pad_sequence([torch.tensor(seq[:max_sequence_length] + [0] * max(0, max_sequence_length - len(seq))) for seq in numericalized_data], batch_first=True, padding_value=0)\n",
        "\n",
        "    print(\"Sample original text:\", data[0][0])  # Print sample original text\n",
        "    print(\"Sample tokenized text:\", tok_reviews[0])  # Print sample tokenized text\n",
        "    print(\"Sample numericalized text:\", numericalized_data[0])  # Print sample numericalized text\n",
        "    print(\"Sample label:\", labels[0])  # Print sample label\n",
        "\n",
        "    return padded_sequences, torch.tensor(labels)\n",
        "\n",
        "# Split data before processing\n",
        "train_ratio = 0.8\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "train_split = int(len(all_data) * train_ratio)\n",
        "val_split = int(len(all_data) * (train_ratio + val_ratio))\n",
        "\n",
        "train_data = all_data[:train_split]\n",
        "val_data = all_data[train_split:val_split]\n",
        "test_data = all_data[val_split:]\n",
        "\n",
        "# Process the datasets\n",
        "x_train_padded, y_train_tensor = preprocess(train_data, vocab)\n",
        "x_val_padded, y_val_tensor = preprocess(val_data, vocab)\n",
        "x_test_padded, y_test_tensor = preprocess(test_data, vocab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IzRM1fRmyHek",
        "outputId": "cf227daf-89f8-4289-8dba-d6b620fdb619"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_padded[10]\n",
        "y_tensor[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "h9bKjp8anllv",
        "outputId": "39224fa5-a60d-4e94-afc6-6bfaccb648ce"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([40000, 512])\n",
            "torch.Size([40000, 1])\n",
            "\n",
            "torch.Size([5000, 512])\n",
            "torch.Size([5000, 1])\n",
            "\n",
            "torch.Size([5000, 512])\n",
            "torch.Size([5000, 1])\n"
          ]
        }
      ],
      "source": [
        "print(x_train_padded.shape)\n",
        "print(y_train_tensor.shape)\n",
        "print()\n",
        "print(x_test_padded.shape)\n",
        "print(y_test_tensor.shape)\n",
        "print()\n",
        "print(x_val_padded.shape)\n",
        "print(y_val_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5-1Z7m7Jn0u"
      },
      "outputs": [],
      "source": [
        "print(x_train_padded.unsqueeze(1)[0])\n",
        "\n",
        "print(type(x_train_padded))\n",
        "print(x_train_padded[0])\n",
        "print(type(x_train_padded[0]))\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "cT6hDF8hFphE",
        "outputId": "3fb58339-b93a-4fe7-91dc-ef5bd252e33a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# Convert data to PyTorch tensors\n",
        "# x_train_tensor = x_train_padded.unsqueeze(1)\n",
        "y_train_tensor = y_train_tensor.unsqueeze(1)\n",
        "# x_val_tensor = x_val_padded.unsqueeze(1)\n",
        "y_val_tensor = y_val_tensor.unsqueeze(1)\n",
        "# x_test_tensor = x_test_padded.unsqueeze(1)\n",
        "y_test_tensor = y_test_tensor.unsqueeze(1)\n",
        "\n",
        "# Create DataLoaders directly with padded data\n",
        "train_dataset = TensorDataset(x_train_padded, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "\n",
        "val_dataset = TensorDataset(x_val_padded, y_val_tensor)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "test_dataset = TensorDataset(x_test_padded, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "################################################################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "no_layers = 2\n",
        "vocab_size = len(vocab) + 1 #extra 1 for padding\n",
        "print(len(vocab))\n",
        "embedding_dim = 256\n",
        "output_dim = 1\n",
        "hidden_dim = 256\n",
        "\n",
        "model = SentimentRNN(no_layers, vocab_size, hidden_dim, embedding_dim, drop_prob=0.5)\n",
        "model.to(device)\n",
        "\n",
        "# loss and optimization functions\n",
        "lr=0.001\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "qxbwwNYZKPd8",
        "outputId": "a283fa72-9b81-42f5-ca3d-e7aa14610bca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "99342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaQxeBiBBkG0"
      },
      "outputs": [],
      "source": [
        "# Assuming train_loader is your DataLoader instance\n",
        "for i, (inputs, labels) in enumerate(val_loader):\n",
        "    print(f\"Batch {i+1}\")\n",
        "\n",
        "    # Print shapes\n",
        "    print(\"Inputs shape:\", inputs.shape)\n",
        "    print(\"Labels shape:\", labels.shape)\n",
        "\n",
        "    # Print actual data\n",
        "    # Depending on your data, you might need to adjust how you print it\n",
        "    print(\"Inputs data:\", inputs)\n",
        "    print(\"Labels data:\", labels)\n",
        "\n",
        "    if i == 10:  # Inspect the first 2 batches\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "jKx5CzeXnJgI",
        "outputId": "b71d11a0-bcec-4192-8f89-c2ebbf133a23"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([40000, 512])\n",
            "torch.Size([40000, 1])\n",
            "\n",
            "torch.Size([5000, 512])\n",
            "torch.Size([5000, 1])\n",
            "\n",
            "torch.Size([5000, 512])\n",
            "torch.Size([5000, 1])\n"
          ]
        }
      ],
      "source": [
        "print(x_train_padded.shape)\n",
        "print(y_train_tensor.shape)\n",
        "print()\n",
        "print(x_test_padded.shape)\n",
        "print(y_test_tensor.shape)\n",
        "print()\n",
        "print(x_val_padded.shape)\n",
        "print(y_val_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "IY3iuVqjd3Lt",
        "outputId": "1cafec32-a929-4e46-9912-de41f34567c4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "train_loss : 0.6935016778469085 val_loss : nan\n",
            "train_accuracy : 49.932500000000005 val_accuracy : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2\n",
            "train_loss : 0.6921476247310638 val_loss : nan\n",
            "train_accuracy : 50.475 val_accuracy : 0.0\n",
            "Epoch 3\n",
            "train_loss : 0.6749001826047898 val_loss : nan\n",
            "train_accuracy : 53.615 val_accuracy : 0.0\n",
            "Epoch 4\n",
            "train_loss : 0.5997357995271683 val_loss : nan\n",
            "train_accuracy : 64.44 val_accuracy : 0.0\n",
            "Epoch 5\n",
            "train_loss : 0.3464973394155502 val_loss : nan\n",
            "train_accuracy : 85.86 val_accuracy : 0.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "batch_size = 32\n",
        "# function to predict accuracy\n",
        "def acc(pred,label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()\n",
        "\n",
        "clip = 5\n",
        "epochs = 5\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "# train for some number of epochs\n",
        "epoch_tr_loss,epoch_vl_loss = [], []\n",
        "epoch_tr_acc,epoch_vl_acc = [], []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    train_losses = []\n",
        "    train_acc = 0.0\n",
        "    model.train()\n",
        "    # initialize hidden state\n",
        "    h = model.init_hidden(batch_size)\n",
        "    for inputs, labels in train_loader:\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        model.zero_grad()\n",
        "        output, h = model(inputs, h)\n",
        "\n",
        "        output = output.view(-1, 1)  # Reshape to [batch_size, 1]\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output, labels.float())\n",
        "        loss.backward()\n",
        "        train_losses.append(loss.item())\n",
        "        # calculating accuracy\n",
        "        accuracy = acc(output,labels.view(-1, 1))\n",
        "        train_acc += accuracy\n",
        "        #`clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "    val_h = model.init_hidden(batch_size)\n",
        "    val_losses = []\n",
        "    val_acc = 0.0\n",
        "    model.eval()\n",
        "\n",
        "    # for inputs, labels in val_loader:\n",
        "    #         val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "    #         inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    #         output, val_h = model(inputs, val_h)\n",
        "\n",
        "    #         output = output.view(-1, 1)\n",
        "    #         val_loss = criterion(output, labels.float())\n",
        "\n",
        "    #         val_losses.append(val_loss.item())\n",
        "\n",
        "    #         accuracy = acc(output, labels.view(-1, 1))\n",
        "    #         val_acc += accuracy\n",
        "\n",
        "    epoch_train_loss = np.mean(train_losses)\n",
        "    epoch_val_loss = np.mean(val_losses)\n",
        "    epoch_train_acc = train_acc/len(train_loader.dataset)\n",
        "    epoch_val_acc = val_acc/len(val_loader.dataset)\n",
        "    epoch_tr_loss.append(epoch_train_loss)\n",
        "    epoch_vl_loss.append(epoch_val_loss)\n",
        "    epoch_tr_acc.append(epoch_train_acc)\n",
        "    epoch_vl_acc.append(epoch_val_acc)\n",
        "    print(f'Epoch {epoch+1}')\n",
        "    print(f'train_loss : {epoch_train_loss} val_loss : {epoch_val_loss}')\n",
        "    print(f'train_accuracy : {epoch_train_acc*100} val_accuracy : {epoch_val_acc*100}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "okyfe6aXELyg",
        "outputId": "d7183ed8-8afb-47d9-8552-4afc72433f30"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.34488716560184574\n",
            "Test accuracy: 87.2%\n"
          ]
        }
      ],
      "source": [
        "# Function for accuracy calculation\n",
        "def acc(pred, label):\n",
        "    pred = torch.round(pred.squeeze())\n",
        "    return torch.sum(pred == label.squeeze()).item()\n",
        "\n",
        "# Testing loop\n",
        "test_losses = []  # to track the loss\n",
        "test_acc = 0.0    # to track the accuracy\n",
        "\n",
        "model.eval()  # turn off dropout for testing\n",
        "\n",
        "# Iterate over the test set\n",
        "for inputs, labels in test_loader:\n",
        "    # Adjust the batch size based on the current batch\n",
        "    current_batch_size = inputs.size(0)\n",
        "    test_h = model.init_hidden(current_batch_size)\n",
        "\n",
        "    test_h = tuple([each.data for each in test_h])  # detach hidden state\n",
        "\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    output, test_h = model(inputs, test_h)\n",
        "    output = output.view(-1, 1)\n",
        "\n",
        "    test_loss = criterion(output, labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "\n",
        "    accuracy = acc(output, labels.view(-1, 1))\n",
        "    test_acc += accuracy\n",
        "\n",
        "# Calculate the average test loss and accuracy\n",
        "avg_test_loss = np.mean(test_losses)\n",
        "avg_test_acc = test_acc / len(test_loader.dataset)\n",
        "\n",
        "# Print the test results\n",
        "print(f'Test loss: {avg_test_loss}')\n",
        "print(f'Test accuracy: {avg_test_acc * 100}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}