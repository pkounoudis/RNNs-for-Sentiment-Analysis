{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML, display\n",
        "\n",
        "def set_css():\n",
        "  display(HTML('''\n",
        "  <style>\n",
        "    pre {\n",
        "        white-space: pre-wrap;\n",
        "    }\n",
        "  </style>\n",
        "  '''))\n",
        "get_ipython().events.register('pre_run_cell', set_css)"
      ],
      "metadata": {
        "id": "wQ95vIqHH_4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ZgtSkovsIBME",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c2668415-1cd0-46eb-a5bb-f24b21ffc23a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3')\n",
        "!pwd"
      ],
      "metadata": {
        "id": "qH2VY7G8IDFu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "648be8c5-3305-4e3d-a654-62b760898a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "f = open('/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3/all_data_IMDB.json')\n",
        "all_data = json.load(f)\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "3-i7jOKlCSj3",
        "outputId": "e9657338-cc68-4b73-b20b-4ccfe07bc532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.shuffle(all_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "KeOa-_UWEh93",
        "outputId": "0f20cc69-bae8-4ec5-fca9-1ecabe994df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "positive_samples = []\n",
        "negative_samples = []\n",
        "count1 = 0\n",
        "count2 = 0\n",
        "\n",
        "for item in range(0, len(all_data)):\n",
        "  if all_data[item][1] == 1:\n",
        "    count1 += 1\n",
        "    positive_samples.append(all_data[item][0])\n",
        "  else:\n",
        "    count2 += 1\n",
        "    negative_samples.append(all_data[item][0])\n",
        "\n",
        "print(\"Positive reviews:\", count1)\n",
        "print(\"Negative reviews:\", count2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "9bPoTn0gCYaO",
        "outputId": "46da3e80-7915-4760-d488-dca307b3cff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive reviews: 25000\n",
            "Negative reviews: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "positive_samples = []\n",
        "positive_directory = '/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3 /IMDB_reviews/aclImdb/train/pos'\n",
        "for filename in os.listdir(positive_directory):\n",
        "    with open(os.path.join(positive_directory, filename), 'r') as file:\n",
        "        positive_samples.append(file.read())"
      ],
      "metadata": {
        "id": "c4z6L8_tuGyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_directory = '/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3 /IMDB_reviews/aclImdb/test/pos'\n",
        "for filename in os.listdir(positive_directory):\n",
        "    with open(os.path.join(positive_directory, filename), 'r') as file:\n",
        "        positive_samples.append(file.read())"
      ],
      "metadata": {
        "id": "oMh5NUxTOuAc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "302c670e-c928-4d43-b002-b4aed78097fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_samples = []\n",
        "negative_directory = '/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3 /IMDB_reviews/aclImdb/train/neg'\n",
        "for filename in os.listdir(negative_directory):\n",
        "    with open(os.path.join(negative_directory, filename), 'r') as file:\n",
        "        negative_samples.append(file.read())"
      ],
      "metadata": {
        "id": "7pKxdsfIuJX3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "507e2a9e-59bb-4092-8181-75ffcd322996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "negative_directory = '/content/drive/MyDrive/Panos/Εργασία DeepLearning/Assignment 2 & 3 /IMDB_reviews/aclImdb/test/pos'\n",
        "for filename in os.listdir(negative_directory):\n",
        "    with open(os.path.join(negative_directory, filename), 'r') as file:\n",
        "        negative_samples.append(file.read())"
      ],
      "metadata": {
        "id": "3mdNhyYzOzf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "088d1ee4-0f4d-4e53-a647-09daf8cd37dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(negative_samples[0])\n",
        "print(negative_samples[1])\n",
        "print()\n",
        "print(positive_samples[0])\n",
        "print(positive_samples[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "sLACLtoniifQ",
        "outputId": "ae8ba904-cb3e-4b9e-8966-01fa8c630c1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "While I don't claim to be any sort of expert in marine life, I must say anyone with a modicum of intelligence could not possibly buy in to this notion of a whale (and not even the mother!) having a clue about revenge because it witnessed his dead mate having a forced abortion by humans! I mean, really! This is basically the whole plot. Richard Harris must have been extremely hard up for roles to have accepted this junk. This is the kind of movie that is so bad that if you paid 50 cents to see it, you would feel like demanding your money back.\n",
            "Oh, those Italians! Assuming that movies about aristocrats with weird fetishes, castles drowned in gothic atmosphere, and back-stabbing relatives trying to get their hands on an inheritance are inherently interesting to all! If you've seen one film of this type, you've basically seen them all (the MST3K favorite \"Screaming Skull\" fits the mold, too)...and \"The Night Evelyn Came Out of the Grave\" is formulaic, by-the-numbers, and dull as hell. Even the luscious Erika Blanc is put to waste here.<br /><br />zero/10<br /><br />\n",
            "\n",
            "What a good film! Made Men is a great action movie with lots of twists and turns. James Belushi is very good as an ex hood who has stolen 12 million from the boss who has to fend of the gangsters , hillbillies his wife and the local sheriff( Timothy Dalton).you wont be disappointed, jump on board and enjoy the ride. 8 out of 10\n",
            "Being the prototype of the classical Errol Flynn adventure movie and having a good story as well as two more brilliant co-stars in Maureen O'Hara (what an exquisite beauty!) and Anthony Quinn, I can only recommend this movie to all those having even the slightest liking for romance and adventure.<br /><br />Hollywood at its best!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "pos_texts= np.array(positive_samples)\n",
        "neg_texts= np.array(negative_samples)\n",
        "pos_labels=  np.array([1]*len(positive_samples))\n",
        "neg_labels=  np.array([0]*len(negative_samples))\n",
        "\n",
        "pos_dataset = pd.DataFrame({'review': pos_texts, 'label': pos_labels}, columns=['review', 'label'])\n",
        "neg_dataset = pd.DataFrame({'review': neg_texts, 'label': neg_labels}, columns=['review', 'label'])"
      ],
      "metadata": {
        "id": "zCmPCS_fJ4Hv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "cbe55f11-a589-4dd0-e7ba-69e3ba3f43ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pos_texts[0])\n",
        "print(neg_texts[0])\n",
        "\n",
        "\n",
        "print(pos_dataset.head(4))\n",
        "print(neg_dataset.head(4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ztMd0fgliYpY",
        "outputId": "452bf9cc-8cfa-4fda-81de-64ffe3a5a137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What a good film! Made Men is a great action movie with lots of twists and turns. James Belushi is very good as an ex hood who has stolen 12 million from the boss who has to fend of the gangsters , hillbillies his wife and the local sheriff( Timothy Dalton).you wont be disappointed, jump on board and enjoy the ride. 8 out of 10\n",
            "While I don't claim to be any sort of expert in marine life, I must say anyone with a modicum of intelligence could not possibly buy in to this notion of a whale (and not even the mother!) having a clue about revenge because it witnessed his dead mate having a forced abortion by humans! I mean, really! This is basically the whole plot. Richard Harris must have been extremely hard up for roles to have accepted this junk. This is the kind of movie that is so bad that if you paid 50 cents to see it, you would feel like demanding your money back.\n",
            "                                              review  label\n",
            "0  What a good film! Made Men is a great action m...      1\n",
            "1  Being the prototype of the classical Errol Fly...      1\n",
            "2  Red Eye, a movie that id had wanted to see for...      1\n",
            "3  I have seen this film many times and I like al...      1\n",
            "                                              review  label\n",
            "0  While I don't claim to be any sort of expert i...      0\n",
            "1  Oh, those Italians! Assuming that movies about...      0\n",
            "2  I really can't understand how could someone gi...      0\n",
            "3  Yes I know \"talkies\" had just been invented fo...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_train = pos_dataset.sample(frac = 0.8)\n",
        "neg_train = neg_dataset.sample(frac = 0.8)\n",
        "pos_part_20 = pos_dataset.drop(pos_train.index)\n",
        "neg_part_20 = neg_dataset.drop(neg_train.index)"
      ],
      "metadata": {
        "id": "vUYRi-5BKvxv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "0f6b293e-920d-4aa6-e4ec-34dff9947874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_test = pos_part_20.sample(frac = 0.5)\n",
        "neg_test = neg_part_20.sample(frac = 0.5)\n",
        "pos_val = pos_part_20.drop(pos_test.index)\n",
        "neg_val = neg_part_20.drop(neg_test.index)"
      ],
      "metadata": {
        "id": "oo79Ca12Lvcx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "71704526-d610-4ed7-985d-eab84e5a0c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set= pd.concat([pos_train, neg_train], axis=0)\n",
        "test_set=pd.concat([pos_test, neg_test], axis=0)\n",
        "val_set=pd.concat([pos_val, neg_val], axis=0)\n",
        "dataset =pd.concat([train_set, test_set,val_set], axis=0)"
      ],
      "metadata": {
        "id": "af5eKV23LWMZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "9d2df15b-c756-4cb9-e73b-db8a7a7a05e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_set.reset_index()\n",
        "test_set = test_set.reset_index()\n",
        "val_set = val_set.reset_index()\n",
        "dataset = dataset.reset_index()"
      ],
      "metadata": {
        "id": "dHiF0XnlNG0v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "6e6b3198-1a4e-4705-abe2-651c321a6fd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Raw data: ')\n",
        "print('max length =',np.max([len(x) for x in dataset['review']]))\n",
        "print('mean length =',np.mean([len(x) for x in dataset['review']]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "mU2I1NNbOljf",
        "outputId": "7fc312d2-11bb-4e6b-c9b3-cd58cdc106b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw data: \n",
            "max length = 8969\n",
            "mean length = 1294.06436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word.isalpha() and word not in stop_words]\n",
        "    words = [lemmatizer.lemmatize(word) for word in words]\n",
        "    return \" \".join(words)\n",
        "\n",
        "train_set['review'] = train_set['review'].apply(normalize_text)\n",
        "val_set['review'] = val_set['review'].apply(normalize_text)\n",
        "test_set['review'] = test_set['review'].apply(normalize_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "UwAW9NbfSeNM",
        "outputId": "35f58cc0-5b64-47bd-a5a3-6be6c7225c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_v2 =pd.concat([train_set, test_set,val_set], axis=0)\n",
        "\n",
        "print('After normalization: ')\n",
        "print('max length =',np.max([len(x) for x in dataset_v2['review']]))\n",
        "print('mean length =',np.mean([len(x) for x in dataset_v2['review']]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "RxGTv6JUTeia",
        "outputId": "3795d5de-4a9e-4030-b628-7d7984b304d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After normalization: \n",
            "max length = 5706\n",
            "mean length = 794.77676\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNKHqH6Pj18N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "540c31c3-ddda-4ab6-eefe-5330d8268201"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After vectorization: \n",
            "max length = 846\n",
            "mean length = 118.49604\n"
          ]
        }
      ],
      "source": [
        "# Import the necessary libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Create the vocabulary from the training dataset\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=30000)\n",
        "tokenizer.fit_on_texts(train_set['review'])\n",
        "vocab_size= len(tokenizer.word_index)+1\n",
        "\n",
        "# Encode the text data as sequences of integers\n",
        "x_train = tokenizer.texts_to_sequences(train_set['review'])\n",
        "x_val = tokenizer.texts_to_sequences(val_set['review'])\n",
        "x_test = tokenizer.texts_to_sequences(test_set['review'])\n",
        "\n",
        "dataset_v3 = x_train + x_val + x_test\n",
        "\n",
        "print('After vectorization: ')\n",
        "print('max length =',np.max([len(x) for x in dataset_v3]))\n",
        "print('mean length =',np.mean([len(x) for x in dataset_v3]))\n",
        "\n",
        "# Pad the sequences to the same length\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=500)\n",
        "x_val = tf.keras.preprocessing.sequence.pad_sequences(x_val, maxlen=500)\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=500)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('After padding: ')\n",
        "print('max length =',np.max([len(x) for x in x_train]))\n",
        "print('mean length =',np.mean([len(x) for x in x_train]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "GkzNmuUvKRke",
        "outputId": "bde3aef1-0358-496a-8572-8fd640c2b175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After padding: \n",
            "max length = 500\n",
            "mean length = 500.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an instance of the LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit and transform the label data\n",
        "y_train = le.fit_transform(train_set['label'])\n",
        "y_val = le.transform(val_set['label'])\n",
        "y_test = le.transform(test_set['label'])\n",
        "\n",
        "# Convert the labels to categorical data\n",
        "y_train = tf.keras.utils.to_categorical(y_train)\n",
        "y_val = tf.keras.utils.to_categorical(y_val)\n",
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ],
      "metadata": {
        "id": "FrvBtoZUPOZJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "803daa22-5f5a-4213-d237-a5debc7a3e1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the GRU model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, 100, input_length=500))\n",
        "model.add(tf.keras.layers.GRU(256))  # Replaced LSTM with GRU\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "score = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print(f'Test loss: {score[0]}')\n",
        "print(f'Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "SRMswP0nlzXQ",
        "outputId": "0c58c258-0584-4a13-a87e-c6802d22f60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1250/1250 [==============================] - 155s 121ms/step - loss: 0.3588 - accuracy: 0.8415 - val_loss: 0.2883 - val_accuracy: 0.8836\n",
            "Epoch 2/5\n",
            "1250/1250 [==============================] - 67s 54ms/step - loss: 0.1688 - accuracy: 0.9374 - val_loss: 0.2714 - val_accuracy: 0.8944\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - 50s 40ms/step - loss: 0.0907 - accuracy: 0.9689 - val_loss: 0.3399 - val_accuracy: 0.8878\n",
            "Epoch 4/5\n",
            "1250/1250 [==============================] - 43s 34ms/step - loss: 0.0425 - accuracy: 0.9859 - val_loss: 0.4476 - val_accuracy: 0.8880\n",
            "Epoch 5/5\n",
            "1250/1250 [==============================] - 45s 36ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.5413 - val_accuracy: 0.8838\n",
            "157/157 [==============================] - 2s 11ms/step - loss: 0.5244 - accuracy: 0.8894\n",
            "Test loss: 0.5243945121765137\n",
            "Test accuracy: 0.8894000053405762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, 100, input_length=500))\n",
        "model.add(tf.keras.layers.LSTM(256))\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "score = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print(f'Test loss: {score[0]}')\n",
        "print(f'Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "YHQVB218s0HW",
        "outputId": "7e6ee081-039c-4166-e8a4-bdd696c24993"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1250/1250 [==============================] - 107s 84ms/step - loss: 0.3585 - accuracy: 0.8466 - val_loss: 0.2932 - val_accuracy: 0.8826\n",
            "Epoch 2/5\n",
            "1250/1250 [==============================] - 55s 44ms/step - loss: 0.1929 - accuracy: 0.9279 - val_loss: 0.2986 - val_accuracy: 0.8864\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - 48s 38ms/step - loss: 0.1632 - accuracy: 0.9389 - val_loss: 0.3653 - val_accuracy: 0.8728\n",
            "Epoch 4/5\n",
            "1250/1250 [==============================] - 43s 35ms/step - loss: 0.1145 - accuracy: 0.9591 - val_loss: 0.3810 - val_accuracy: 0.8678\n",
            "Epoch 5/5\n",
            "1250/1250 [==============================] - 43s 34ms/step - loss: 0.0632 - accuracy: 0.9787 - val_loss: 0.4886 - val_accuracy: 0.8768\n",
            "157/157 [==============================] - 2s 12ms/step - loss: 0.5027 - accuracy: 0.8764\n",
            "Test loss: 0.5026859641075134\n",
            "Test accuracy: 0.8763999938964844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN-LSTM model\n",
        "model = tf.keras.Sequential()\n",
        "# Embedding layer\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, 100, input_length=500))\n",
        "# Convolutional Layer\n",
        "model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
        "# LSTM Layer\n",
        "model.add(tf.keras.layers.LSTM(256))\n",
        "# Output Layer\n",
        "model.add(tf.keras.layers.Dense(2, activation='sigmoid'))  # Assuming binary classification\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Model summary\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "score = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print(f'Test loss: {score[0]}')\n",
        "print(f'Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "id": "iLprFp7TwTLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "outputId": "e9950c69-df6b-40c8-fc44-d10d3057438e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 500, 100)          8176300   \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 496, 128)          64128     \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPoolin  (None, 248, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " lstm_5 (LSTM)               (None, 256)               394240    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8635182 (32.94 MB)\n",
            "Trainable params: 8635182 (32.94 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1250/1250 [==============================] - 101s 76ms/step - loss: 0.3454 - accuracy: 0.8489 - val_loss: 0.2673 - val_accuracy: 0.8942\n",
            "Epoch 2/5\n",
            "1250/1250 [==============================] - 44s 35ms/step - loss: 0.1695 - accuracy: 0.9377 - val_loss: 0.2732 - val_accuracy: 0.8896\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - 36s 29ms/step - loss: 0.0857 - accuracy: 0.9717 - val_loss: 0.3434 - val_accuracy: 0.8912\n",
            "Epoch 4/5\n",
            "1250/1250 [==============================] - 32s 26ms/step - loss: 0.0377 - accuracy: 0.9875 - val_loss: 0.4100 - val_accuracy: 0.8830\n",
            "Epoch 5/5\n",
            "1250/1250 [==============================] - 29s 23ms/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.5228 - val_accuracy: 0.8828\n",
            "157/157 [==============================] - 1s 9ms/step - loss: 0.5235 - accuracy: 0.8822\n",
            "Test loss: 0.5234784483909607\n",
            "Test accuracy: 0.8822000026702881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN-GRU model\n",
        "model = tf.keras.Sequential()\n",
        "# Embedding layer\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, 100, input_length=500))\n",
        "# Convolutional Layer\n",
        "model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
        "# GRU Layer\n",
        "model.add(tf.keras.layers.GRU(256))  # Replacing LSTM with GRU\n",
        "# Output Layer - Assuming binary classification with 2 classes, using sigmoid activation\n",
        "model.add(tf.keras.layers.Dense(2, activation='sigmoid'))\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Model summary to view the architecture\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "score = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print(f'Test loss: {score[0]}')\n",
        "print(f'Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "zr3J2PJBJDkk",
        "outputId": "2cf2447e-1b49-430f-fd93-50932be110bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 500, 100)          8176300   \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 496, 128)          64128     \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPoolin  (None, 248, 128)          0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 256)               296448    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 514       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8537390 (32.57 MB)\n",
            "Trainable params: 8537390 (32.57 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "1250/1250 [==============================] - 96s 75ms/step - loss: 0.3275 - accuracy: 0.8543 - val_loss: 0.2532 - val_accuracy: 0.8990\n",
            "Epoch 2/5\n",
            "1250/1250 [==============================] - 45s 36ms/step - loss: 0.1431 - accuracy: 0.9473 - val_loss: 0.2970 - val_accuracy: 0.8886\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - 32s 25ms/step - loss: 0.0512 - accuracy: 0.9825 - val_loss: 0.4059 - val_accuracy: 0.8818\n",
            "Epoch 4/5\n",
            "1250/1250 [==============================] - 30s 24ms/step - loss: 0.0204 - accuracy: 0.9931 - val_loss: 0.5093 - val_accuracy: 0.8772\n",
            "Epoch 5/5\n",
            "1250/1250 [==============================] - 28s 23ms/step - loss: 0.0136 - accuracy: 0.9954 - val_loss: 0.6338 - val_accuracy: 0.8820\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.6104 - accuracy: 0.8866\n",
            "Test loss: 0.6103944778442383\n",
            "Test accuracy: 0.8866000175476074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN model\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, 100, input_length=500))\n",
        "model.add(tf.keras.layers.Conv1D(512, 5, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(.3))\n",
        "model.add(tf.keras.layers.MaxPooling1D(5))\n",
        "model.add(tf.keras.layers.Conv1D(512, 5, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(.2))\n",
        "model.add(tf.keras.layers.MaxPooling1D(5))\n",
        "model.add(tf.keras.layers.Conv1D(512, 5, activation='relu'))\n",
        "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "score = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print(f'Test loss: {score[0]}')\n",
        "print(f'Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9thEic4s5O0",
        "outputId": "8cd58828-9206-498f-d018-3ec0df68da13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1250/1250 [==============================] - 114s 85ms/step - loss: 0.6935 - accuracy: 0.4965 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 2/5\n",
            "1250/1250 [==============================] - 53s 42ms/step - loss: 0.6932 - accuracy: 0.4997 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
            "Epoch 3/5\n",
            "1250/1250 [==============================] - 41s 33ms/step - loss: 0.6932 - accuracy: 0.5023 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 4/5\n",
            "1250/1250 [==============================] - 38s 30ms/step - loss: 0.6932 - accuracy: 0.4981 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Epoch 5/5\n",
            "1250/1250 [==============================] - 42s 34ms/step - loss: 0.6294 - accuracy: 0.6205 - val_loss: 0.5997 - val_accuracy: 0.6660\n",
            "157/157 [==============================] - 1s 8ms/step - loss: 0.5975 - accuracy: 0.6652\n",
            "Test loss: 0.5975179076194763\n",
            "Test accuracy: 0.6651999950408936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the CNN-LSTM-GRU model\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# Embedding layer\n",
        "model.add(tf.keras.layers.Embedding(vocab_size, 100, input_length=500))\n",
        "# Convolutional Layer for feature extraction\n",
        "model.add(tf.keras.layers.Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))\n",
        "# LSTM Layer\n",
        "model.add(tf.keras.layers.LSTM(128, return_sequences=True))  # return_sequences=True for stacking\n",
        "# GRU Layer, added after LSTM layer\n",
        "model.add(tf.keras.layers.GRU(128))  # Stacked upon LSTM\n",
        "# Output Layer - Assuming binary classification\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # Use 1 unit for binary classification\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# Model summary to view the architecture\n",
        "model.summary()\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the model on the test dataset\n",
        "score = model.evaluate(x_test, y_test, batch_size=32)\n",
        "print(f'Test loss: {score[0]}')\n",
        "print(f'Test accuracy: {score[1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 841
        },
        "id": "O36BtLu8NlkP",
        "outputId": "4089a3b5-9e15-431e-dd66-a6f7a9115275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "  <style>\n",
              "    pre {\n",
              "        white-space: pre-wrap;\n",
              "    }\n",
              "  </style>\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 100)          5789600   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 496, 128)          64128     \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 248, 128)          0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 248, 128)          131584    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               99072     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6084513 (23.21 MB)\n",
            "Trainable params: 6084513 (23.21 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 83s 124ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 9.6396e-07 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "129/625 [=====>........................] - ETA: 37s - loss: 9.4699e-07 - accuracy: 1.0000"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f29d923a5a13>\u001b[0m in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Evaluate the model on the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}